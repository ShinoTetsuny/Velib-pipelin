# ğŸš€ Batch Processing - Velib Analytics

## ğŸ“Š FonctionnalitÃ©s Batch

### Analyses effectuÃ©es :
- **ğŸ† Top 10 stations** avec le plus de vÃ©los disponibles
- **ğŸ˜ï¸ Statistiques par arrondissement** (capacitÃ©, vÃ©los disponibles)
- **ğŸ“ˆ Taux de disponibilitÃ©** des stations
- **ğŸ’¾ Export des rÃ©sultats** en CSV dans HDFS

## ğŸš€ Comment lancer

### 1. DÃ©marrer le cluster
```bash
docker-compose up -d
```

### 2. Initialiser les donnÃ©es
```bash
docker exec namenode hdfs dfs -mkdir -p /users/ipssi/input/velib2
docker exec namenode hdfs dfs -mkdir -p /users/ipssi/output
docker cp app/velib.csv namenode:/tmp/velib.csv
docker exec namenode hdfs dfs -put /tmp/velib.csv /users/ipssi/input/velib2/
```

### 3. Lancer les analyses
```bash
chmod +x run-batch.sh
./run-batch.sh
```

## ğŸ“ RÃ©sultats

Les rÃ©sultats sont sauvegardÃ©s dans HDFS :
- `/users/ipssi/output/top_stations/` - Top 10 stations
- `/users/ipssi/output/stats_arrondissement/` - Stats par arrondissement  
- `/users/ipssi/output/taux_disponibilite/` - Taux de disponibilitÃ©

## ğŸ” VÃ©rifier les rÃ©sultats

```bash
# Voir les fichiers gÃ©nÃ©rÃ©s
docker exec namenode hdfs dfs -ls /users/ipssi/output/

# Voir le contenu des rÃ©sultats
docker exec namenode hdfs dfs -cat /users/ipssi/output/top_stations/part-00000-*.csv | head -5
```

## ğŸŒ Interfaces web

- **Hadoop** : http://localhost:9870
- **Spark** : http://localhost:8080
- **YARN** : http://localhost:8088

## ğŸ“Š Dashboard Streamlit

### Lancer le frontend
```bash
chmod +x run-streamlit.sh
./run-streamlit.sh
```

### AccÃ©der au dashboard
- **URL** : http://localhost:8501
- **FonctionnalitÃ©s** : 8 pages d'analyse interactives
- **Graphiques** : Barres, lignes, scatter, pie charts
- **Filtres** : Par arrondissement, date, vÃ©los

## ğŸ› ï¸ Commandes utiles

```bash
# ArrÃªter le cluster
docker-compose down

# Voir les logs
docker-compose logs spark-master

# RedÃ©marrer
docker-compose restart
```

---
**âœ… PrÃªt ! Vos analyses Batch sont terminÃ©es.**
