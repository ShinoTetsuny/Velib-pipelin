# ğŸš€ Batch Processing - Velib Analytics

## ğŸ“Š FonctionnalitÃ©s Batch

### Analyses effectuÃ©es :
- **ğŸ† Top 10 stations** avec le plus de vÃ©los disponibles
- **ğŸ˜ï¸ Statistiques par arrondissement** (capacitÃ©, vÃ©los disponibles)
- **ğŸ“ˆ Taux de disponibilitÃ©** des stations
- **ğŸ’¾ Export des rÃ©sultats** en CSV dans HDFS

## ğŸš€ Comment lancer

### 1. DÃ©marrer le cluster
```bash
docker-compose up -d
```

### 2. Initialiser les donnÃ©es
```bash
docker exec namenode hdfs dfs -mkdir -p /users/ipssi/input/velib2
docker exec namenode hdfs dfs -mkdir -p /users/ipssi/output
docker cp app/velib.csv namenode:/tmp/velib.csv
docker exec namenode hdfs dfs -put /tmp/velib.csv /users/ipssi/input/velib2/
```

### 3. Lancer les analyses
```bash
chmod +x run-batch.sh
./run-batch.sh
```

### 4. Planifier l'exÃ©cution quotidienne (24h)
```bash
# Planifier l'exÃ©cution automatique Ã  02:00 chaque jour
./schedule-batch.sh --schedule

# ExÃ©cuter immÃ©diatement
./schedule-batch.sh --run-batch

# Voir les logs
./schedule-batch.sh --logs

# ArrÃªter la planification
./schedule-batch.sh --stop
```

## ğŸ“ RÃ©sultats

Les rÃ©sultats sont sauvegardÃ©s dans **MongoDB ET HDFS** :
- **MongoDB** : Collections `top_stations`, `stats_arrondissement`, `taux_disponibilite`
- **HDFS** : `/users/ipssi/output/top_stations/` - Top 10 stations
- **HDFS** : `/users/ipssi/output/stats_arrondissement/` - Stats par arrondissement  
- **HDFS** : `/users/ipssi/output/taux_disponibilite/` - Taux de disponibilitÃ©

## â° Mise Ã  jour automatique

### Planifier l'exÃ©cution quotidienne (toutes les 24h)
```bash
# Planifier Ã  02:00 tous les jours
./schedule-batch.sh --schedule

# ExÃ©cuter immÃ©diatement
./schedule-batch.sh --run-batch

# Voir les logs
./schedule-batch.sh --logs

# ArrÃªter la planification
./schedule-batch.sh --stop
```

## ğŸ” VÃ©rifier les rÃ©sultats

```bash
# Voir les fichiers gÃ©nÃ©rÃ©s HDFS
docker exec namenode hdfs dfs -ls /users/ipssi/output/

# Voir le contenu des rÃ©sultats HDFS
docker exec namenode hdfs dfs -cat /users/ipssi/output/top_stations/part-00000-*.csv | head -5

# VÃ©rifier les donnÃ©es MongoDB
./test-mongodb.sh

# Ou manuellement
docker exec -it mongodb-ipssi mongosh
use velib
db.top_stations.find().limit(5)
```

## ğŸŒ Interfaces web

- **Hadoop** : http://localhost:9870
- **Spark** : http://localhost:8080
- **YARN** : http://localhost:8088

## ğŸ“Š Dashboard Streamlit

### Lancer le frontend
```bash
chmod +x run-streamlit.sh
./run-streamlit.sh
```

### AccÃ©der au dashboard
- **URL** : http://localhost:8501
- **FonctionnalitÃ©s** : 8 pages d'analyse interactives
- **Graphiques** : Barres, lignes, scatter, pie charts
- **Filtres** : Par arrondissement, date, vÃ©los

## ğŸ› ï¸ Commandes utiles

```bash
# ArrÃªter le cluster
docker-compose down

# Voir les logs
docker-compose logs spark-master

# RedÃ©marrer
docker-compose restart
```

---
**âœ… PrÃªt ! Vos analyses Batch sont terminÃ©es.**
